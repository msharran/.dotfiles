{"id":"c57fd725-ff35-442c-8b91-c98271aa1041","zed":"context","version":"0.4.0","text":"\n\n\n```zig /home/msharran/.cache/zig/p/12205b2b47fe61a4cde3a45ee4b9cddee75897739dbc196d6396e117cb1ce28e1ad0/src/watcher/tcp.zig\nconst std = @import(\"std\");\nconst builtin = @import(\"builtin\");\nconst assert = std.debug.assert;\nconst posix = std.posix;\nconst stream = @import(\"stream.zig\");\nconst common = @import(\"common.zig\");\n\n/// TCP client and server.\n///\n/// This is a \"higher-level abstraction\" in libxev. The goal of higher-level\n/// abstractions in libxev are to make it easier to use specific functionality\n/// with the event loop, but does not promise perfect flexibility or optimal\n/// performance. In almost all cases, the abstraction is good enough. But,\n/// if you have specific needs or want to push for the most optimal performance,\n/// use the platform-specific Loop directly.\npub fn TCP(comptime xev: type) type {\n    return struct {\n        const Self = @This();\n        const FdType = if (xev.backend == .iocp) std.os.windows.HANDLE else posix.socket_t;\n\n        fd: FdType,\n\n        pub usingnamespace stream.Stream(xev, Self, .{\n            .close = true,\n            .read = .recv,\n            .write = .send,\n        });\n\n        /// Initialize a new TCP with the family from the given address. Only\n        /// the family is used, the actual address has no impact on the created\n        /// resource.\n        pub fn init(addr: std.net.Address) !Self {\n            if (xev.backend == .wasi_poll) @compileError(\"unsupported in WASI\");\n\n            const fd = if (xev.backend == .iocp)\n                try std.os.windows.WSASocketW(addr.any.family, posix.SOCK.STREAM, 0, null, 0, std.os.windows.ws2_32.WSA_FLAG_OVERLAPPED)\n            else fd: {\n                // On io_uring we don't use non-blocking sockets because we may\n                // just get EAGAIN over and over from completions.\n                const flags = flags: {\n                    var flags: u32 = posix.SOCK.STREAM | posix.SOCK.CLOEXEC;\n                    if (xev.backend != .io_uring) flags |= posix.SOCK.NONBLOCK;\n                    break :flags flags;\n                };\n                break :fd try posix.socket(addr.any.family, flags, 0);\n            };\n\n            return .{\n                .fd = fd,\n            };\n        }\n\n        /// Initialize a TCP socket from a file descriptor.\n        pub fn initFd(fd: FdType) Self {\n            return .{\n                .fd = fd,\n            };\n        }\n\n        /// Bind the address to the socket.\n        pub fn bind(self: Self, addr: std.net.Address) !void {\n            if (xev.backend == .wasi_poll) @compileError(\"unsupported in WASI\");\n\n            const fd = if (xev.backend == .iocp) @as(std.os.windows.ws2_32.SOCKET, @ptrCast(self.fd)) else self.fd;\n\n            try posix.setsockopt(fd, posix.SOL.SOCKET, posix.SO.REUSEADDR, &std.mem.toBytes(@as(c_int, 1)));\n            try posix.bind(fd, &addr.any, addr.getOsSockLen());\n        }\n\n        /// Listen for connections on the socket. This puts the socket into passive\n        /// listening mode. Connections must still be accepted one at a time.\n        pub fn listen(self: Self, backlog: u31) !void {\n            if (xev.backend == .wasi_poll) @compileError(\"unsupported in WASI\");\n\n            const fd = if (xev.backend == .iocp) @as(std.os.windows.ws2_32.SOCKET, @ptrCast(self.fd)) else self.fd;\n\n            try posix.listen(fd, backlog);\n        }\n\n        /// Accept a single connection.\n        pub fn accept(\n            self: Self,\n            loop: *xev.Loop,\n            c: *xev.Completion,\n            comptime Userdata: type,\n            userdata: ?*Userdata,\n            comptime cb: *const fn (\n                ud: ?*Userdata,\n                l: *xev.Loop,\n                c: *xev.Completion,\n                r: AcceptError!Self,\n            ) xev.CallbackAction,\n        ) void {\n            c.* = .{\n                .op = .{\n                    .accept = .{\n                        .socket = self.fd,\n                    },\n                },\n\n                .userdata = userdata,\n                .callback = (struct {\n                    fn callback(\n                        ud: ?*anyopaque,\n                        l_inner: *xev.Loop,\n                        c_inner: *xev.Completion,\n                        r: xev.Result,\n                    ) xev.CallbackAction {\n                        return @call(.always_inline, cb, .{\n                            common.userdataValue(Userdata, ud),\n                            l_inner,\n                            c_inner,\n                            if (r.accept) |fd| initFd(fd) else |err| err,\n                        });\n                    }\n                }).callback,\n            };\n\n            // If we're dup-ing, then we ask the backend to manage the fd.\n            switch (xev.backend) {\n                .io_uring,\n                .kqueue,\n                .wasi_poll,\n                .iocp,\n                => {},\n\n                .epoll => c.flags.dup = true,\n            }\n\n            loop.add(c);\n        }\n\n        /// Establish a connection as a client.\n        pub fn connect(\n            self: Self,\n            loop: *xev.Loop,\n            c: *xev.Completion,\n            addr: std.net.Address,\n            comptime Userdata: type,\n            userdata: ?*Userdata,\n            comptime cb: *const fn (\n                ud: ?*Userdata,\n                l: *xev.Loop,\n                c: *xev.Completion,\n                s: Self,\n                r: ConnectError!void,\n            ) xev.CallbackAction,\n        ) void {\n            if (xev.backend == .wasi_poll) @compileError(\"unsupported in WASI\");\n\n            c.* = .{\n                .op = .{\n                    .connect = .{\n                        .socket = self.fd,\n                        .addr = addr,\n                    },\n                },\n\n                .userdata = userdata,\n                .callback = (struct {\n                    fn callback(\n                        ud: ?*anyopaque,\n                        l_inner: *xev.Loop,\n                        c_inner: *xev.Completion,\n                        r: xev.Result,\n                    ) xev.CallbackAction {\n                        return @call(.always_inline, cb, .{\n                            common.userdataValue(Userdata, ud),\n                            l_inner,\n                            c_inner,\n                            initFd(c_inner.op.connect.socket),\n                            if (r.connect) |_| {} else |err| err,\n                        });\n                    }\n                }).callback,\n            };\n\n            loop.add(c);\n        }\n\n        /// Shutdown the socket. This always only shuts down the writer side. You\n        /// can use the lower level interface directly to control this if the\n        /// platform supports it.\n        pub fn shutdown(\n            self: Self,\n            loop: *xev.Loop,\n            c: *xev.Completion,\n            comptime Userdata: type,\n            userdata: ?*Userdata,\n            comptime cb: *const fn (\n                ud: ?*Userdata,\n                l: *xev.Loop,\n                c: *xev.Completion,\n                s: Self,\n                r: ShutdownError!void,\n            ) xev.CallbackAction,\n        ) void {\n            c.* = .{\n                .op = .{\n                    .shutdown = .{\n                        .socket = self.fd,\n                        .how = .send,\n                    },\n                },\n                .userdata = userdata,\n                .callback = (struct {\n                    fn callback(\n                        ud: ?*anyopaque,\n                        l_inner: *xev.Loop,\n                        c_inner: *xev.Completion,\n                        r: xev.Result,\n                    ) xev.CallbackAction {\n                        return @call(.always_inline, cb, .{\n                            common.userdataValue(Userdata, ud),\n                            l_inner,\n                            c_inner,\n                            initFd(c_inner.op.shutdown.socket),\n                            if (r.shutdown) |_| {} else |err| err,\n                        });\n                    }\n                }).callback,\n            };\n\n            loop.add(c);\n        }\n\n        pub const AcceptError = xev.AcceptError;\n        pub const ConnectError = xev.ConnectError;\n        pub const ShutdownError = xev.ShutdownError;\n\n        test \"TCP: accept/connect/send/recv/close\" {\n            // We have no way to get a socket in WASI from a WASI context.\n            if (xev.backend == .wasi_poll) return error.SkipZigTest;\n\n            const testing = std.testing;\n\n            var loop = try xev.Loop.init(.{});\n            defer loop.deinit();\n\n            // Choose random available port (Zig #14907)\n            var address = try std.net.Address.parseIp4(\"127.0.0.1\", 0);\n            const server = try Self.init(address);\n\n            // Bind and listen\n            try server.bind(address);\n            try server.listen(1);\n\n            // Retrieve bound port and initialize client\n            var sock_len = address.getOsSockLen();\n            const fd = if (xev.backend == .iocp) @as(std.os.windows.ws2_32.SOCKET, @ptrCast(server.fd)) else server.fd;\n            try posix.getsockname(fd, &address.any, &sock_len);\n            const client = try Self.init(address);\n\n            //const address = try std.net.Address.parseIp4(\"127.0.0.1\", 3132);\n            //var server = try Self.init(address);\n            //var client = try Self.init(address);\n\n            // Completions we need\n            var c_accept: xev.Completion = undefined;\n            var c_connect: xev.Completion = undefined;\n\n            // Accept\n            var server_conn: ?Self = null;\n            server.accept(&loop, &c_accept, ?Self, &server_conn, (struct {\n                fn callback(\n                    ud: ?*?Self,\n                    _: *xev.Loop,\n                    _: *xev.Completion,\n                    r: AcceptError!Self,\n                ) xev.CallbackAction {\n                    ud.?.* = r catch unreachable;\n                    return .disarm;\n                }\n            }).callback);\n\n            // Connect\n            var connected: bool = false;\n            client.connect(&loop, &c_connect, address, bool, &connected, (struct {\n                fn callback(\n                    ud: ?*bool,\n                    _: *xev.Loop,\n                    _: *xev.Completion,\n                    _: Self,\n                    r: ConnectError!void,\n                ) xev.CallbackAction {\n                    _ = r catch unreachable;\n                    ud.?.* = true;\n                    return .disarm;\n                }\n            }).callback);\n\n            // Wait for the connection to be established\n            try loop.run(.until_done);\n            try testing.expect(server_conn != null);\n            try testing.expect(connected);\n\n            // Close the server\n            var server_closed = false;\n            server.close(&loop, &c_accept, bool, &server_closed, (struct {\n                fn callback(\n                    ud: ?*bool,\n                    _: *xev.Loop,\n                    _: *xev.Completion,\n                    _: Self,\n                    r: Self.CloseError!void,\n                ) xev.CallbackAction {\n                    _ = r catch unreachable;\n                    ud.?.* = true;\n                    return .disarm;\n                }\n            }).callback);\n            try loop.run(.until_done);\n            try testing.expect(server_closed);\n\n            // Send\n            var send_buf = [_]u8{ 1, 1, 2, 3, 5, 8, 13 };\n            client.write(&loop, &c_connect, .{ .slice = &send_buf }, void, null, (struct {\n                fn callback(\n                    _: ?*void,\n                    _: *xev.Loop,\n                    c: *xev.Completion,\n                    _: Self,\n                    _: xev.WriteBuffer,\n                    r: Self.WriteError!usize,\n                ) xev.CallbackAction {\n                    _ = c;\n                    _ = r catch unreachable;\n                    return .disarm;\n                }\n            }).callback);\n\n            // Receive\n            var recv_buf: [128]u8 = undefined;\n            var recv_len: usize = 0;\n            server_conn.?.read(&loop, &c_accept, .{ .slice = &recv_buf }, usize, &recv_len, (struct {\n                fn callback(\n                    ud: ?*usize,\n                    _: *xev.Loop,\n                    _: *xev.Completion,\n                    _: Self,\n                    _: xev.ReadBuffer,\n                    r: Self.ReadError!usize,\n                ) xev.CallbackAction {\n                    ud.?.* = r catch unreachable;\n                    return .disarm;\n                }\n            }).callback);\n\n            // Wait for the send/receive\n            try loop.run(.until_done);\n            try testing.expectEqualSlices(u8, &send_buf, recv_buf[0..recv_len]);\n\n            // Close\n            server_conn.?.close(&loop, &c_accept, ?Self, &server_conn, (struct {\n                fn callback(\n                    ud: ?*?Self,\n                    _: *xev.Loop,\n                    _: *xev.Completion,\n                    _: Self,\n                    r: Self.CloseError!void,\n                ) xev.CallbackAction {\n                    _ = r catch unreachable;\n                    ud.?.* = null;\n                    return .disarm;\n                }\n            }).callback);\n            client.close(&loop, &c_connect, bool, &connected, (struct {\n                fn callback(\n                    ud: ?*bool,\n                    _: *xev.Loop,\n                    _: *xev.Completion,\n                    _: Self,\n                    r: Self.CloseError!void,\n                ) xev.CallbackAction {\n                    _ = r catch unreachable;\n                    ud.?.* = false;\n                    return .disarm;\n                }\n            }).callback);\n\n            try loop.run(.until_done);\n            try testing.expect(server_conn == null);\n            try testing.expect(!connected);\n            try testing.expect(server_closed);\n        }\n\n        // Potentially flaky - this test could hang if the sender is unable to\n        // write everything to the socket for whatever reason\n        // (e.g. incorrectly sized buffer on the receiver side), or if the\n        // receiver is trying to receive while sender has nothing left to send.\n        //\n        // Overview:\n        // 1. Set up server and client sockets\n        // 2. connect & accept, set SO_SNDBUF to 8kB on the client\n        // 3. Try to send 1MB buffer from client to server without queuing, this _should_ fail\n        //    and theoretically send <= 8kB, but in practice, it seems to write ~32kB.\n        //    Asserts that <= 100kB was written\n        // 4. Set up a queued write with the remaining buffer, shutdown() the socket afterwards\n        // 5. Set up a receiver that loops until it receives the entire buffer\n        // 6. Assert send_buf == recv_buf\n        test \"TCP: Queued writes\" {\n            // We have no way to get a socket in WASI from a WASI context.\n            if (xev.backend == .wasi_poll) return error.SkipZigTest;\n            // Windows doesn't seem to respect the SNDBUF socket option.\n            if (builtin.os.tag == .windows) return error.SkipZigTest;\n\n            const testing = std.testing;\n\n            var loop = try xev.Loop.init(.{});\n            defer loop.deinit();\n\n            // Choose random available port (Zig #14907)\n            var address = try std.net.Address.parseIp4(\"127.0.0.1\", 0);\n            const server = try Self.init(address);\n\n            // Bind and listen\n            try server.bind(address);\n            try server.listen(1);\n\n            // Retrieve bound port and initialize client\n            var sock_len = address.getOsSockLen();\n            try posix.getsockname(server.fd, &address.any, &sock_len);\n            const client = try Self.init(address);\n\n            // Completions we need\n            var c_accept: xev.Completion = undefined;\n            var c_connect: xev.Completion = undefined;\n\n            // Accept\n            var server_conn: ?Self = null;\n            server.accept(&loop, &c_accept, ?Self, &server_conn, (struct {\n                fn callback(\n                    ud: ?*?Self,\n                    _: *xev.Loop,\n                    _: *xev.Completion,\n                    r: AcceptError!Self,\n                ) xev.CallbackAction {\n                    ud.?.* = r catch unreachable;\n                    return .disarm;\n                }\n            }).callback);\n\n            // Connect\n            var connected: bool = false;\n            client.connect(&loop, &c_connect, address, bool, &connected, (struct {\n                fn callback(\n                    ud: ?*bool,\n                    _: *xev.Loop,\n                    _: *xev.Completion,\n                    _: Self,\n                    r: ConnectError!void,\n                ) xev.CallbackAction {\n                    _ = r catch unreachable;\n                    ud.?.* = true;\n                    return .disarm;\n                }\n            }).callback);\n\n            // Wait for the connection to be established\n            try loop.run(.until_done);\n            try testing.expect(server_conn != null);\n            try testing.expect(connected);\n\n            // Close the server\n            var server_closed = false;\n            server.close(&loop, &c_accept, bool, &server_closed, (struct {\n                fn callback(\n                    ud: ?*bool,\n                    _: *xev.Loop,\n                    _: *xev.Completion,\n                    _: Self,\n                    r: Self.CloseError!void,\n                ) xev.CallbackAction {\n                    _ = r catch unreachable;\n                    ud.?.* = true;\n                    return .disarm;\n                }\n            }).callback);\n            try loop.run(.until_done);\n            try testing.expect(server_closed);\n\n            // Unqueued send - Limit send buffer to 8kB, this should force partial writes.\n            try posix.setsockopt(client.fd, posix.SOL.SOCKET, posix.SO.SNDBUF, &std.mem.toBytes(@as(c_int, 8192)));\n\n            const send_buf = [_]u8{ 1, 2, 3, 4, 5, 6, 7, 8, 9, 0 } ** 100_000;\n            var sent_unqueued: usize = 0;\n\n            // First we try to send the whole 1MB buffer in one write operation, this _should_ result\n            // in a partial write.\n            client.write(&loop, &c_connect, .{ .slice = &send_buf }, usize, &sent_unqueued, (struct {\n                fn callback(\n                    sent_unqueued_inner: ?*usize,\n                    _: *xev.Loop,\n                    _: *xev.Completion,\n                    _: Self,\n                    _: xev.WriteBuffer,\n                    r: Self.WriteError!usize,\n                ) xev.CallbackAction {\n                    sent_unqueued_inner.?.* = r catch unreachable;\n                    return .disarm;\n                }\n            }).callback);\n\n            // Make sure that we sent a small fraction of the buffer\n            try loop.run(.until_done);\n            // SO_SNDBUF doesn't seem to be respected exactly, sent_unqueued will often be ~32kB\n            // even though SO_SNDBUF was set to 8kB\n            try testing.expect(sent_unqueued < (send_buf.len / 10));\n\n            // Set up queued write\n            var w_queue = Self.WriteQueue{};\n            var wr_send: xev.TCP.WriteRequest = undefined;\n            var sent_queued: usize = 0;\n            const queued_slice = send_buf[sent_unqueued..];\n            client.queueWrite(&loop, &w_queue, &wr_send, .{ .slice = queued_slice }, usize, &sent_queued, (struct {\n                fn callback(\n                    sent_queued_inner: ?*usize,\n                    l: *xev.Loop,\n                    c: *xev.Completion,\n                    tcp: Self,\n                    _: xev.WriteBuffer,\n                    r: Self.WriteError!usize,\n                ) xev.CallbackAction {\n                    sent_queued_inner.?.* = r catch unreachable;\n\n                    tcp.shutdown(l, c, void, null, (struct {\n                        fn callback(\n                            _: ?*void,\n                            _: *xev.Loop,\n                            _: *xev.Completion,\n                            _: Self,\n                            _: Self.ShutdownError!void,\n                        ) xev.CallbackAction {\n                            return .disarm;\n                        }\n                    }).callback);\n\n                    return .disarm;\n                }\n            }).callback);\n\n            // Set up receiver which is going to keep reading until it reads the full\n            // send buffer\n            const Receiver = struct {\n                loop: *xev.Loop,\n                conn: Self,\n                completion: xev.Completion = .{},\n                buf: [send_buf.len]u8 = undefined,\n                bytes_read: usize = 0,\n\n                pub fn read(receiver: *@This()) void {\n                    if (receiver.bytes_read == receiver.buf.len) return;\n\n                    const read_buf = xev.ReadBuffer{\n                        .slice = receiver.buf[receiver.bytes_read..],\n                    };\n                    receiver.conn.read(receiver.loop, &receiver.completion, read_buf, @This(), receiver, readCb);\n                }\n\n                pub fn readCb(\n                    receiver_opt: ?*@This(),\n                    _: *xev.Loop,\n                    _: *xev.Completion,\n                    _: Self,\n                    _: xev.ReadBuffer,\n                    r: Self.ReadError!usize,\n                ) xev.CallbackAction {\n                    var receiver = receiver_opt.?;\n                    const n_bytes = r catch unreachable;\n\n                    receiver.bytes_read += n_bytes;\n                    if (receiver.bytes_read < send_buf.len) {\n                        receiver.read();\n                    }\n\n                    return .disarm;\n                }\n            };\n            var receiver = Receiver{\n                .loop = &loop,\n                .conn = server_conn.?,\n            };\n            receiver.read();\n\n            // Wait for the send/receive\n            try loop.run(.until_done);\n            try testing.expectEqualSlices(u8, &send_buf, receiver.buf[0..receiver.bytes_read]);\n            try testing.expect(send_buf.len == sent_unqueued + sent_queued);\n\n            // Close\n            server_conn.?.close(&loop, &c_accept, ?Self, &server_conn, (struct {\n                fn callback(\n                    ud: ?*?Self,\n                    _: *xev.Loop,\n                    _: *xev.Completion,\n                    _: Self,\n                    r: Self.CloseError!void,\n                ) xev.CallbackAction {\n                    _ = r catch unreachable;\n                    ud.?.* = null;\n                    return .disarm;\n                }\n            }).callback);\n            client.close(&loop, &c_connect, bool, &connected, (struct {\n                fn callback(\n                    ud: ?*bool,\n                    _: *xev.Loop,\n                    _: *xev.Completion,\n                    _: Self,\n                    r: Self.CloseError!void,\n                ) xev.CallbackAction {\n                    _ = r catch unreachable;\n                    ud.?.* = false;\n                    return .disarm;\n                }\n            }).callback);\n\n            try loop.run(.until_done);\n            try testing.expect(server_conn == null);\n            try testing.expect(!connected);\n            try testing.expect(server_closed);\n        }\n    };\n}\n```\n\n```zig /snap/zig/11624/lib/std/mem/Allocator.zig\n//! The standard memory allocation interface.\n\nconst std = @import(\"../std.zig\");\nconst assert = std.debug.assert;\nconst math = std.math;\nconst mem = std.mem;\nconst Allocator = @This();\nconst builtin = @import(\"builtin\");\n\npub const Error = error{OutOfMemory};\npub const Log2Align = math.Log2Int(usize);\n\n// The type erased pointer to the allocator implementation\nptr: *anyopaque,\nvtable: *const VTable,\n\npub const VTable = struct {\n    /// Attempt to allocate exactly `len` bytes aligned to `1 << ptr_align`.\n    ///\n    /// `ret_addr` is optionally provided as the first return address of the\n    /// allocation call stack. If the value is `0` it means no return address\n    /// has been provided.\n    alloc: *const fn (ctx: *anyopaque, len: usize, ptr_align: u8, ret_addr: usize) ?[*]u8,\n\n    /// Attempt to expand or shrink memory in place. `buf.len` must equal the\n    /// length requested from the most recent successful call to `alloc` or\n    /// `resize`. `buf_align` must equal the same value that was passed as the\n    /// `ptr_align` parameter to the original `alloc` call.\n    ///\n    /// A result of `true` indicates the resize was successful and the\n    /// allocation now has the same address but a size of `new_len`. `false`\n    /// indicates the resize could not be completed without moving the\n    /// allocation to a different address.\n    ///\n    /// `new_len` must be greater than zero.\n    ///\n    /// `ret_addr` is optionally provided as the first return address of the\n    /// allocation call stack. If the value is `0` it means no return address\n    /// has been provided.\n    resize: *const fn (ctx: *anyopaque, buf: []u8, buf_align: u8, new_len: usize, ret_addr: usize) bool,\n\n    /// Free and invalidate a buffer.\n    ///\n    /// `buf.len` must equal the most recent length returned by `alloc` or\n    /// given to a successful `resize` call.\n    ///\n    /// `buf_align` must equal the same value that was passed as the\n    /// `ptr_align` parameter to the original `alloc` call.\n    ///\n    /// `ret_addr` is optionally provided as the first return address of the\n    /// allocation call stack. If the value is `0` it means no return address\n    /// has been provided.\n    free: *const fn (ctx: *anyopaque, buf: []u8, buf_align: u8, ret_addr: usize) void,\n};\n\npub fn noResize(\n    self: *anyopaque,\n    buf: []u8,\n    log2_buf_align: u8,\n    new_len: usize,\n    ret_addr: usize,\n) bool {\n    _ = self;\n    _ = buf;\n    _ = log2_buf_align;\n    _ = new_len;\n    _ = ret_addr;\n    return false;\n}\n\npub fn noFree(\n    self: *anyopaque,\n    buf: []u8,\n    log2_buf_align: u8,\n    ret_addr: usize,\n) void {\n    _ = self;\n    _ = buf;\n    _ = log2_buf_align;\n    _ = ret_addr;\n}\n\n/// This function is not intended to be called except from within the\n/// implementation of an Allocator\npub inline fn rawAlloc(self: Allocator, len: usize, ptr_align: u8, ret_addr: usize) ?[*]u8 {\n    return self.vtable.alloc(self.ptr, len, ptr_align, ret_addr);\n}\n\n/// This function is not intended to be called except from within the\n/// implementation of an Allocator\npub inline fn rawResize(self: Allocator, buf: []u8, log2_buf_align: u8, new_len: usize, ret_addr: usize) bool {\n    return self.vtable.resize(self.ptr, buf, log2_buf_align, new_len, ret_addr);\n}\n\n/// This function is not intended to be called except from within the\n/// implementation of an Allocator\npub inline fn rawFree(self: Allocator, buf: []u8, log2_buf_align: u8, ret_addr: usize) void {\n    return self.vtable.free(self.ptr, buf, log2_buf_align, ret_addr);\n}\n\n/// Returns a pointer to undefined memory.\n/// Call `destroy` with the result to free the memory.\npub fn create(self: Allocator, comptime T: type) Error!*T {\n    if (@sizeOf(T) == 0) return @as(*T, @ptrFromInt(math.maxInt(usize)));\n    const ptr: *T = @ptrCast(try self.allocBytesWithAlignment(@alignOf(T), @sizeOf(T), @returnAddress()));\n    return ptr;\n}\n\n/// `ptr` should be the return value of `create`, or otherwise\n/// have the same address and alignment property.\npub fn destroy(self: Allocator, ptr: anytype) void {\n    const info = @typeInfo(@TypeOf(ptr)).Pointer;\n    if (info.size != .One) @compileError(\"ptr must be a single item pointer\");\n    const T = info.child;\n    if (@sizeOf(T) == 0) return;\n    const non_const_ptr = @as([*]u8, @ptrCast(@constCast(ptr)));\n    self.rawFree(non_const_ptr[0..@sizeOf(T)], log2a(info.alignment), @returnAddress());\n}\n\n/// Allocates an array of `n` items of type `T` and sets all the\n/// items to `undefined`. Depending on the Allocator\n/// implementation, it may be required to call `free` once the\n/// memory is no longer needed, to avoid a resource leak. If the\n/// `Allocator` implementation is unknown, then correct code will\n/// call `free` when done.\n///\n/// For allocating a single item, see `create`.\npub fn alloc(self: Allocator, comptime T: type, n: usize) Error![]T {\n    return self.allocAdvancedWithRetAddr(T, null, n, @returnAddress());\n}\n\npub fn allocWithOptions(\n    self: Allocator,\n    comptime Elem: type,\n    n: usize,\n    /// null means naturally aligned\n    comptime optional_alignment: ?u29,\n    comptime optional_sentinel: ?Elem,\n) Error!AllocWithOptionsPayload(Elem, optional_alignment, optional_sentinel) {\n    return self.allocWithOptionsRetAddr(Elem, n, optional_alignment, optional_sentinel, @returnAddress());\n}\n\npub fn allocWithOptionsRetAddr(\n    self: Allocator,\n    comptime Elem: type,\n    n: usize,\n    /// null means naturally aligned\n    comptime optional_alignment: ?u29,\n    comptime optional_sentinel: ?Elem,\n    return_address: usize,\n) Error!AllocWithOptionsPayload(Elem, optional_alignment, optional_sentinel) {\n    if (optional_sentinel) |sentinel| {\n        const ptr = try self.allocAdvancedWithRetAddr(Elem, optional_alignment, n + 1, return_address);\n        ptr[n] = sentinel;\n        return ptr[0..n :sentinel];\n    } else {\n        return self.allocAdvancedWithRetAddr(Elem, optional_alignment, n, return_address);\n    }\n}\n\nfn AllocWithOptionsPayload(comptime Elem: type, comptime alignment: ?u29, comptime sentinel: ?Elem) type {\n    if (sentinel) |s| {\n        return [:s]align(alignment orelse @alignOf(Elem)) Elem;\n    } else {\n        return []align(alignment orelse @alignOf(Elem)) Elem;\n    }\n}\n\n/// Allocates an array of `n + 1` items of type `T` and sets the first `n`\n/// items to `undefined` and the last item to `sentinel`. Depending on the\n/// Allocator implementation, it may be required to call `free` once the\n/// memory is no longer needed, to avoid a resource leak. If the\n/// `Allocator` implementation is unknown, then correct code will\n/// call `free` when done.\n///\n/// For allocating a single item, see `create`.\npub fn allocSentinel(\n    self: Allocator,\n    comptime Elem: type,\n    n: usize,\n    comptime sentinel: Elem,\n) Error![:sentinel]Elem {\n    return self.allocWithOptionsRetAddr(Elem, n, null, sentinel, @returnAddress());\n}\n\npub fn alignedAlloc(\n    self: Allocator,\n    comptime T: type,\n    /// null means naturally aligned\n    comptime alignment: ?u29,\n    n: usize,\n) Error![]align(alignment orelse @alignOf(T)) T {\n    return self.allocAdvancedWithRetAddr(T, alignment, n, @returnAddress());\n}\n\npub inline fn allocAdvancedWithRetAddr(\n    self: Allocator,\n    comptime T: type,\n    /// null means naturally aligned\n    comptime alignment: ?u29,\n    n: usize,\n    return_address: usize,\n) Error![]align(alignment orelse @alignOf(T)) T {\n    const a = alignment orelse @alignOf(T);\n    const ptr: [*]align(a) T = @ptrCast(try self.allocWithSizeAndAlignment(@sizeOf(T), a, n, return_address));\n    return ptr[0..n];\n}\n\nfn allocWithSizeAndAlignment(self: Allocator, comptime size: usize, comptime alignment: u29, n: usize, return_address: usize) Error![*]align(alignment) u8 {\n    const byte_count = math.mul(usize, size, n) catch return Error.OutOfMemory;\n    return self.allocBytesWithAlignment(alignment, byte_count, return_address);\n}\n\nfn allocBytesWithAlignment(self: Allocator, comptime alignment: u29, byte_count: usize, return_address: usize) Error![*]align(alignment) u8 {\n    // The Zig Allocator interface is not intended to solve alignments beyond\n    // the minimum OS page size. For these use cases, the caller must use OS\n    // APIs directly.\n    comptime assert(alignment <= mem.page_size);\n\n    if (byte_count == 0) {\n        const ptr = comptime std.mem.alignBackward(usize, math.maxInt(usize), alignment);\n        return @as([*]align(alignment) u8, @ptrFromInt(ptr));\n    }\n\n    const byte_ptr = self.rawAlloc(byte_count, log2a(alignment), return_address) orelse return Error.OutOfMemory;\n    // TODO: https://github.com/ziglang/zig/issues/4298\n    @memset(byte_ptr[0..byte_count], undefined);\n    return @as([*]align(alignment) u8, @alignCast(byte_ptr));\n}\n\n/// Requests to modify the size of an allocation. It is guaranteed to not move\n/// the pointer, however the allocator implementation may refuse the resize\n/// request by returning `false`.\npub fn resize(self: Allocator, old_mem: anytype, new_n: usize) bool {\n    const Slice = @typeInfo(@TypeOf(old_mem)).Pointer;\n    const T = Slice.child;\n    if (new_n == 0) {\n        self.free(old_mem);\n        return true;\n    }\n    if (old_mem.len == 0) {\n        return false;\n    }\n    const old_byte_slice = mem.sliceAsBytes(old_mem);\n    // I would like to use saturating multiplication here, but LLVM cannot lower it\n    // on WebAssembly: https://github.com/ziglang/zig/issues/9660\n    //const new_byte_count = new_n *| @sizeOf(T);\n    const new_byte_count = math.mul(usize, @sizeOf(T), new_n) catch return false;\n    return self.rawResize(old_byte_slice, log2a(Slice.alignment), new_byte_count, @returnAddress());\n}\n\n/// This function requests a new byte size for an existing allocation, which\n/// can be larger, smaller, or the same size as the old memory allocation.\n/// If `new_n` is 0, this is the same as `free` and it always succeeds.\npub fn realloc(self: Allocator, old_mem: anytype, new_n: usize) t: {\n    const Slice = @typeInfo(@TypeOf(old_mem)).Pointer;\n    break :t Error![]align(Slice.alignment) Slice.child;\n} {\n    return self.reallocAdvanced(old_mem, new_n, @returnAddress());\n}\n\npub fn reallocAdvanced(\n    self: Allocator,\n    old_mem: anytype,\n    new_n: usize,\n    return_address: usize,\n) t: {\n    const Slice = @typeInfo(@TypeOf(old_mem)).Pointer;\n    break :t Error![]align(Slice.alignment) Slice.child;\n} {\n    const Slice = @typeInfo(@TypeOf(old_mem)).Pointer;\n    const T = Slice.child;\n    if (old_mem.len == 0) {\n        return self.allocAdvancedWithRetAddr(T, Slice.alignment, new_n, return_address);\n    }\n    if (new_n == 0) {\n        self.free(old_mem);\n        const ptr = comptime std.mem.alignBackward(usize, math.maxInt(usize), Slice.alignment);\n        return @as([*]align(Slice.alignment) T, @ptrFromInt(ptr))[0..0];\n    }\n\n    const old_byte_slice = mem.sliceAsBytes(old_mem);\n    const byte_count = math.mul(usize, @sizeOf(T), new_n) catch return Error.OutOfMemory;\n    // Note: can't set shrunk memory to undefined as memory shouldn't be modified on realloc failure\n    if (mem.isAligned(@intFromPtr(old_byte_slice.ptr), Slice.alignment)) {\n        if (self.rawResize(old_byte_slice, log2a(Slice.alignment), byte_count, return_address)) {\n            const new_bytes: []align(Slice.alignment) u8 = @alignCast(old_byte_slice.ptr[0..byte_count]);\n            return mem.bytesAsSlice(T, new_bytes);\n        }\n    }\n\n    const new_mem = self.rawAlloc(byte_count, log2a(Slice.alignment), return_address) orelse\n        return error.OutOfMemory;\n    const copy_len = @min(byte_count, old_byte_slice.len);\n    @memcpy(new_mem[0..copy_len], old_byte_slice[0..copy_len]);\n    // TODO https://github.com/ziglang/zig/issues/4298\n    @memset(old_byte_slice, undefined);\n    self.rawFree(old_byte_slice, log2a(Slice.alignment), return_address);\n\n    const new_bytes: []align(Slice.alignment) u8 = @alignCast(new_mem[0..byte_count]);\n    return mem.bytesAsSlice(T, new_bytes);\n}\n\n/// Free an array allocated with `alloc`. To free a single item,\n/// see `destroy`.\npub fn free(self: Allocator, memory: anytype) void {\n    const Slice = @typeInfo(@TypeOf(memory)).Pointer;\n    const bytes = mem.sliceAsBytes(memory);\n    const bytes_len = bytes.len + if (Slice.sentinel != null) @sizeOf(Slice.child) else 0;\n    if (bytes_len == 0) return;\n    const non_const_ptr = @constCast(bytes.ptr);\n    // TODO: https://github.com/ziglang/zig/issues/4298\n    @memset(non_const_ptr[0..bytes_len], undefined);\n    self.rawFree(non_const_ptr[0..bytes_len], log2a(Slice.alignment), @returnAddress());\n}\n\n/// Copies `m` to newly allocated memory. Caller owns the memory.\npub fn dupe(allocator: Allocator, comptime T: type, m: []const T) Error![]T {\n    const new_buf = try allocator.alloc(T, m.len);\n    @memcpy(new_buf, m);\n    return new_buf;\n}\n\n/// Copies `m` to newly allocated memory, with a null-terminated element. Caller owns the memory.\npub fn dupeZ(allocator: Allocator, comptime T: type, m: []const T) Error![:0]T {\n    const new_buf = try allocator.alloc(T, m.len + 1);\n    @memcpy(new_buf[0..m.len], m);\n    new_buf[m.len] = 0;\n    return new_buf[0..m.len :0];\n}\n\n/// TODO replace callsites with `@log2` after this proposal is implemented:\n/// https://github.com/ziglang/zig/issues/13642\ninline fn log2a(x: anytype) switch (@typeInfo(@TypeOf(x))) {\n    .Int => math.Log2Int(@TypeOf(x)),\n    .ComptimeInt => comptime_int,\n    else => @compileError(\"int please\"),\n} {\n    switch (@typeInfo(@TypeOf(x))) {\n        .Int => return math.log2_int(@TypeOf(x), x),\n        .ComptimeInt => return math.log2(x),\n        else => @compileError(\"bad\"),\n    }\n}\n```\n\n```zig zig-redis-server/src/Server.zig\nconst std = @import(\"std\");\nconst log = std.log.scoped(.server);\nconst net = std.net;\nconst posix = std.posix;\n\nconst Server = @This();\nconst Dictionary = @import(\"Dictionary.zig\");\nconst Router = @import(\"Router.zig\");\nconst Resp = @import(\"Resp.zig\");\nconst Request = @import(\"command.zig\").Request;\nconst ThreadPool = std.Thread.Pool;\nconst xev = @import(\"xev\");\nconst TCP = xev.TCP;\n\n/// router is responsible for handling the commands received by the server.\nrouter: Router,\n\n/// allocator is used to allocate memory for the server.\nallocator: std.mem.Allocator,\n\ndict: *Dictionary,\n\n/// pool is used to handle incoming connections concurrently.\npool: *ThreadPool,\n\n/// init allocates memory for the server.\n/// Caller should call self.deinit to free the memory.\npub fn init(allocator: std.mem.Allocator) !Server {\n    const obj_store = try Dictionary.init(allocator);\n    const router = try Router.init(allocator);\n\n    const opt = ThreadPool.Options{\n        .n_jobs = 4, // TODO: Make this configurable\n        .allocator = allocator,\n    };\n    var pool = try allocator.create(ThreadPool);\n    try pool.init(opt);\n\n    return Server{\n        .allocator = allocator,\n        .router = router,\n        .dict = obj_store,\n        .pool = pool,\n    };\n}\n\npub fn deinit(self: *Server) void {\n    defer std.debug.print(\"Server deinitialised\", .{});\n\n    self.pool.deinit();\n    self.allocator.destroy(self.pool);\n    self.dict.deinit();\n    self.router.deinit();\n    self.* = undefined;\n}\n\nconst RingBuffer = struct {\n    inner: std.fifo.LinearFifo(u8, .{ .Static = 4096 }),\n    completion: xev.Completion = undefined,\n    loop: *xev.Loop = undefined,\n    tcp: xev.TCP = undefined,\n    allocator: std.mem.Allocator,\n\n    pub fn init(allocator: std.mem.Allocator) !RingBuffer {\n        return RingBuffer{\n            .inner = std.fifo.LinearFifo(u8, .{ .Static = 4096 }).init(),\n            .allocator = allocator,\n        };\n    }\n\n    pub fn deinit(self: *RingBuffer) void {\n        self.inner.deinit();\n    }\n\n    pub fn write(self: *RingBuffer, loop: *xev.Loop, tcp: xev.TCP, data: []const u8) !void {\n        self.loop = loop;\n        self.tcp = tcp;\n\n        tcp.write(loop, &self.completion, .{ .slice = data }, void, null, (struct {\n            fn callback(_: ?*void, l: *xev.Loop, c: *xev.Completion, t: xev.TCP, _: xev.WriteBuffer, r: xev.WriteError!usize) xev.CallbackAction {\n                _ = l;\n                _ = c;\n                _ = t;\n                if (r) |_| {\n                    return .disarm;\n                } else |err| {\n                    log.err(\"Write error: {}\", .{err});\n                    return .disarm;\n                }\n            }\n        }).callback);\n    }\n\n    pub fn read(self: *RingBuffer, loop: *xev.Loop, tcp: xev.TCP) !void {\n        self.loop = loop;\n        self.tcp = tcp;\n\n        var read_buf: [4096]u8 = undefined;\n        tcp.read(loop, &self.completion, .{ .slice = &read_buf }, void, null, (struct {\n            fn callback(rb: ?*void, l: *xev.Loop, c: *xev.Completion, t: xev.TCP, buffer: xev.ReadBuffer, r: xev.ReadError!usize) xev.CallbackAction {\n                if (r) |size| {\n                    const self_rb = @as(*RingBuffer, @ptrCast(@alignCast(rb.?)));\n                    self_rb.inner.write(buffer.slice[0..size]) catch |err| {\n                        log.err(\"Buffer write error: {}\", .{err});\n                        return .disarm;\n                    };\n                    return .rearm;\n                } else |err| {\n                    if (err != error.EOF) {\n                        log.err(\"Read error: {}\", .{err});\n                    }\n                    return .disarm;\n                }\n            }\n        }).callback);\n    }\n\n    pub fn readByte(self: *RingBuffer) ?u8 {\n        return self.inner.readItem();\n    }\n\n    pub fn peekByte(self: *RingBuffer) ?u8 {\n        if (self.inner.count == 0) return null;\n        return self.inner.buf[self.inner.head];\n    }\n\n    pub fn readAll(self: *RingBuffer, buffer: []u8) usize {\n        return self.inner.read(buffer);\n    }\n};\npub fn listenAndServe(self: *Server, address: std.net.Address) !void {\n    const tpe: u32 = posix.SOCK.STREAM;\n    const protocol = posix.IPPROTO.TCP;\n    const listener = try posix.socket(address.any.family, tpe, protocol);\n    defer posix.close(listener);\n\n    // TODO: Implement ring buffer for reading and writing\n    // https://discord.com/channels/1085221098129473637/1179194569800294550/1329122172685516860\n    while (true) {\n        var client_address: net.Address = undefined;\n        var client_address_len: posix.socklen_t = @sizeOf(net.Address);\n\n        const connection: posix.socket_t = posix.accept(listener, &client_address.any, &client_address_len, 0) catch |err| {\n            log.err(\"Failed to accept connection: {}\", .{err});\n            return;\n        };\n        errdefer posix.close(connection);\n\n        self.handle_connection(connection);\n        // self.pool.spawn(handle_connection, .{ self, connection }) catch |err| {\n        //     log.err(\"Failed to spawn worker: {}\", .{err});\n        // };\n    }\n}\n\nfn handle_connection(self: *Server, connection: posix.socket_t) void {\n    defer posix.close(connection);\n\n    var buf: [4028]u8 = undefined;\n    const read = posix.read(connection, &buf) catch |err| {\n        log.err(\"Failed to read from client: {}\", .{err});\n        return;\n    };\n\n    if (read == 0) {\n        log.info(\"Read 0 bytes from client, closing connection\", .{});\n        return;\n    }\n\n    const resp = Resp.init(self.allocator);\n    defer resp.deinit();\n\n    const msg = resp.deserialise(buf[0..read]) catch |err| {\n        log.err(\"Failed to deserialise message: {}\", .{err});\n        return;\n    };\n\n    const req = Request{ .message = msg, .dict = self.dict };\n    const resp_msg = self.router.route(req);\n\n    const raw_msg = resp.serialise(resp_msg) catch |err| {\n        log.err(\"Failed to serialise message: {}\", .{err});\n        return;\n    };\n\n    writeAll(connection, raw_msg) catch |err| {\n        log.err(\"Failed to write to client: {}\", .{err});\n    };\n}\n\nfn writeAll(socket: posix.socket_t, msg: []const u8) !void {\n    var pos: usize = 0;\n    while (pos < msg.len) {\n        const written = try posix.write(socket, msg[pos..]);\n        if (written == 0) {\n            return error.Closed;\n        }\n        pos += written;\n    }\n}\n```\n\n\nGenerate code for listening and serving on a TCP socket \nusing xev library using the same listenAndServe function\nand Server struct as in the Zig code above.\nMake the code NON Blocking IO using the xev library.\n\nHere's a modified version of the `listenAndServe` function using the xev library for non-blocking I/O:\n\n```zig\npub fn listenAndServe(self: *Server, address: std.net.Address) !void {\n    var loop = try xev.Loop.init(.{});\n    defer loop.deinit();\n\n    // Initialize TCP server\n    const server = try TCP(.{ .init = true }).init(address);\n    defer server.deinit();\n\n    // Bind and listen\n    try server.bind(address);\n    try server.listen(128);\n\n    // Completion for accept\n    var accept_completion: xev.Completion = undefined;\n\n    // Accept loop\n    while (true) {\n        server.accept(\n            &loop,\n            &accept_completion,\n            *Server,\n            self,\n            (struct {\n                fn callback(\n                    srv: ?**Server,\n                    l: *xev.Loop,\n                    c: *xev.Completion,\n                    result: TCP(.{ init = true }).AcceptError!TCP(.{ .init = true }),\n                ) xev.CallbackAction {\n                    const connection = result catch |err| {\n                        log.err(\"Accept error: {}\", .{err});\n                        return .rearm;\n                    };\n\n                    // Handle the new connection\n                    handleConnectionXev(srv.?.*, l, connection) catch |err| {\n                        log.err(\"Connection handling error: {}\", .{err});\n                    };\n\n                    return .rearm;\n                }\n            }).callback,\n        );\n\n        // Run the event loop\n        try loop.run(.until_done);\n    }\n}\n\nfn handleConnectionXev(self: *Server, loop: *xev.Loop, connection: TCP(.{ .init = true })) !void {\n    var ring_buffer = try RingBuffer.init(self.allocator);\n    defer ring_buffer.deinit();\n\n    // Start reading from the connection\n    try ring_buffer.read(loop, connection);\n\n    while (true) {\n        try loop.run(.until_done);\n\n        var buf: [4096]u8 = undefined;\n        const bytes_read = ring_buffer.readAll(&buf);\n        if (bytes_read == 0) continue;\n\n        const resp = Resp.init(self.allocator);\n        defer resp.deinit();\n\n        const msg = try resp.deserialise(buf[0..bytes_read]);\n        const req = Request{ .message = msg, .dict = self.dict };\n        const resp_msg = self.router.route(req);\n\n        const raw_msg = try resp.serialise(resp_msg);\n        try ring_buffer.write(loop, connection, raw_msg);\n    }\n}\n```\n\nThis implementation:\n\n1. Uses xev's event loop for non-blocking I/O operations\n2. Creates a TCP server using xev's TCP type\n3. Uses callbacks for handling accept operations\n4. Utilizes the RingBuffer struct you already have for buffering reads and writes\n5. Maintains the same message processing logic but in a non-blocking way\n\nKey changes:\n\n1. The server now uses an event loop instead of blocking accept calls\n2. Connection handling is done through callbacks\n3. Reading and writing are non-blocking operations\n4. The RingBuffer is used to manage partial reads and writes\n\nThe code assumes that your RingBuffer implementation is already compatible with xev's non-blocking operations. If it's not, you might need to modify it to better handle partial reads and writes.\n\nTo make this work even better, you might want to consider:\n\n1. Adding connection tracking to properly clean up resources\n2. Implementing proper error handling for connection drops\n3. Adding timeouts for read/write operations\n4. Implementing proper connection pooling\n5. Adding graceful shutdown handling\n\nAlso, you might want to add configuration options for:\n\n1. Maximum number of concurrent connections\n2. Read/write buffer sizes\n3. Connection timeouts\n4. Backlog size for listen()\n\nLet me know if you need any clarification or have specific requirements that need to be addressed!\n","messages":[{"id":{"replica_id":0,"value":0},"start":0,"metadata":{"role":"user","status":"Done","timestamp":{"replica_id":0,"value":143}}},{"id":{"replica_id":0,"value":82},"start":43919,"metadata":{"role":"assistant","status":"Done","timestamp":{"replica_id":0,"value":144}}},{"id":{"replica_id":0,"value":83},"start":47662,"metadata":{"role":"user","status":"Done","timestamp":{"replica_id":0,"value":145}}}],"summary":"TCP Server with xev NonBlocking IO","slash_command_output_sections":[{"range":{"start":0,"end":1},"icon":"Library","label":"Default","metadata":null},{"range":{"start":3,"end":23614},"icon":"File","label":"/home/msharran/.cache/zig/p/12205b2b47fe61a4cde3a45ee4b9cddee75897739dbc196d6396e117cb1ce28e1ad0/src/watcher/tcp.zig","metadata":{"path":"/home/msharran/.cache/zig/p/12205b2b47fe61a4cde3a45ee4b9cddee75897739dbc196d6396e117cb1ce28e1ad0/src/watcher/tcp.zig"}},{"range":{"start":23615,"end":37294},"icon":"File","label":"/snap/zig/11624/lib/std/mem/Allocator.zig","metadata":{"path":"/snap/zig/11624/lib/std/mem/Allocator.zig"}},{"range":{"start":37295,"end":43705},"icon":"File","label":"zig-redis-server/src/Server.zig","metadata":{"path":"zig-redis-server/src/Server.zig"}}]}